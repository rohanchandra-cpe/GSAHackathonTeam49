{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-24T21:25:29.976089Z",
     "start_time": "2024-07-24T21:25:29.930405Z"
    }
   },
   "outputs": [],
   "source": [
    "import cohere\n",
    "import uuid\n",
    "import hnswlib\n",
    "from typing import List, Dict\n",
    "from unstructured.partition.html import partition_html\n",
    "from unstructured.chunking.title import chunk_by_title\n",
    "\n",
    "# Cohere API key\n",
    "api_key = 'BfTJNyke3jghhXpgRy6R1SSl8fRpso5o02i78moX'\n",
    "\n",
    "# Set up Cohere client\n",
    "co = cohere.Client(api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create the VectorStore Component\n",
    "\n",
    "The Vectorstore class handles the ingestion of documents into embeddings (or vectors) and the retrieval of relevant documents given a query.\n",
    "\n",
    "As an example, we’ll use the contents from LLM University: What are Large Language Models? which explains the architecture of large language models. It consists of four web pages, each in the Python list raw_documents below. Each entry is identified by its title and URL.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8fdc7616f82e5506"
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "raw_documents = [\n",
    "    {\n",
    "        \"title\": \"Text Embeddings\",\n",
    "        \"url\": \"https://docs.cohere.com/docs/text-embeddings\"},\n",
    "    {\n",
    "        \"title\": \"Similarity Between Words and Sentences\",\n",
    "        \"url\": \"https://docs.cohere.com/docs/similarity-between-words-and-sentences\"},\n",
    "    {\n",
    "        \"title\": \"The Attention Mechanism\",\n",
    "        \"url\": \"https://docs.cohere.com/docs/the-attention-mechanism\"},\n",
    "    {\n",
    "        \"title\": \"Transformer Models\",\n",
    "        \"url\": \"https://docs.cohere.com/docs/transformer-models\"}\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-24T21:25:40.502588Z",
     "start_time": "2024-07-24T21:25:40.474548Z"
    }
   },
   "id": "b2aade2a2ccb41bf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We implement this in the Vectorstore class below, which takes the raw_documents list as input.\n",
    "\n",
    "We also initialize a few instance attributes and methods. The attributes include self.raw_documents to represent the raw documents, self.docs to represent the chunked version of the documents, self.docs_embs to represent the embeddings of the chunked documents, and a couple of top_k parameters to be used for retrieval and reranking.\n",
    "\n",
    "Meanwhile, the methods include load_and_chunk(), embed(), and index() for ingesting raw documents. As you’ll see, we will also specify a retrieve() method to retrieve relevant document chunks given a query.\n",
    "\n",
    "## Load and Chunk the Documents\n",
    "The load_and_chunk() method loads the raw documents from the URL and breaks them into smaller chunks. Chunking for information retrieval is a broad topic in and of itself, with many strategies being discussed within the AI community. For our example, we’ll utilize the partition_html method from the unstructured library. Read its documentation for more information about its chunking approach.\n",
    "\n",
    "Each chunk is turned into a dictionary with three fields:\n",
    "\n",
    "title: The web page’s title\n",
    "text: The textual content of the chunk\n",
    "url: The web page’s URL\n",
    "This information will eventually be passed to the chatbot’s prompt for generating the response, so it’s crucial to populate relevant information into this dictionary. Note that we are not limited to these three fields. At a minimum, the Chat endpoint requires the text field, but beyond that, we can add custom fields that can provide more context about the document, such as subtitles, snippets, tags, and others.\n",
    "\n",
    "The resulting dictionaries are stored in the self.docs attribute.\n",
    "\n",
    "## Embed the Document Chunks\n",
    "The embed() method generates embeddings of the chunked documents. We use the Embed endpoint and Cohere's embed-english-v3.0 model. Since the endpoint has a limit of 96 documents per call, we send them in batches.\n",
    "\n",
    "With the Embed v3 model, we need to define an input_type, of which there are four options depending on the type of task. Using these input types ensures the highest possible quality for the respective tasks. Since our document chunks will be used for retrieval, we use search_document as the input_type.\n",
    "\n",
    "The resulting chunk embeddings are stored in the self.docs_embs attribute.\n",
    "\n",
    "## Index Document Chunks\n",
    "The index() method indexes the document chunk embeddings. We build an index to store the embeddings in a structured and organized way in order to ensure efficient similarity search during retrieval.\n",
    "\n",
    "There are many options available for building an index. For production environments, typically a vector database (like Weaviate or MongoDB) is required to handle the continuous process of indexing documents and maintaining the index.\n",
    "\n",
    "In our example, however, we’ll keep it simple and use a vector library instead. We can choose from many open-source projects, such as Faiss, Annoy, ScaNN, or Hnswlib, which is the one we’ll use. These libraries store embeddings in in-memory indexes and implement approximate nearest neighbor (ANN) algorithms to make similarity search efficient.\n",
    "\n",
    "The resulting document chunk embeddings are stored in the self.idx attribute.\n",
    "\n",
    "## Implement Retrieval\n",
    "The retrieve() method uses semantic search to retrieve relevant document chunks given a query, and it has two steps: (1) dense retrieval, (2) reranking.\n",
    "### Dense Retrieval\n",
    "We implement a dense retrieval system that leverages embeddings to retrieve document chunks, offering significant improvements over basic keyword-matching approaches. Embeddings can capture the contextual meaning of a document, thus enabling the retrieval of highly relevant results to the given query.\n",
    "\n",
    "We embed the query using the same embed-english-v3.0 model that we used to embed the document chunks, but this time, we set input_type=”search_query”.\n",
    "\n",
    "Search is performed by the knn_query() method from the hnswlib library. Given a query, it returns the document chunks most similar to the query. We define the number of document chunks to return using the attribute self.retrieve_top_k=10.\n",
    "\n",
    "### Reranking\n",
    "After dense retrieval, we implement a reranking step. While our dense retrieval component is already highly capable of retrieving relevant sources, the Rerank endpoint provides an additional boost to the quality of the search results, especially for complex and domain-specific queries. It takes the search results and sorts them according to their relevance to the query.\n",
    "\n",
    "We call the Rerank endpoint with co.rerank() and pass the query and the list of document chunks to be reranked. We also define the number of top reranked document chunks to retrieve using the attribute self.rerank_top_k=3. The model we use is rerank-english-v3.0, which lets you rerank documents that contain multiple fields, in the form of JSON objects. In our case, we'll use the title and text fields for reranking.\n",
    "\n",
    "This method returns the top retrieved document chunks as a Python list docs_retrieved, so that they can be passed to the chatbot, which we’ll implement next."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8af5e01f6ff75801"
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "class Vectorstore:\n",
    "    def __init__(self, raw_documents: List[Dict[str, str]]):\n",
    "        self.raw_documents = raw_documents\n",
    "        self.docs = []\n",
    "        self.docs_embs = []\n",
    "        self.retrieve_top_k = 10\n",
    "        self.rerank_top_k = 3\n",
    "        self.load_and_chunk()\n",
    "        self.embed()\n",
    "        self.index()\n",
    "        \n",
    "    def load_and_chunk(self) -> None:\n",
    "        \"\"\"\n",
    "        Loads the text from the sources and chunks the HTML content.\n",
    "        \"\"\"\n",
    "        print(\"Loading documents...\")\n",
    "\n",
    "        for raw_document in self.raw_documents:\n",
    "            elements = partition_html(url=raw_document[\"url\"])\n",
    "            chunks = chunk_by_title(elements)\n",
    "            for chunk in chunks:\n",
    "                self.docs.append(\n",
    "                    {\n",
    "                        \"title\": raw_document[\"title\"],\n",
    "                        \"text\": str(chunk),\n",
    "                        \"url\": raw_document[\"url\"],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    def embed(self) -> None:\n",
    "        \"\"\"\n",
    "        Embeds the document chunks using the Cohere API.\n",
    "        \"\"\"\n",
    "        print(\"Embedding document chunks...\")\n",
    "\n",
    "        batch_size = 90\n",
    "        self.docs_len = len(self.docs)\n",
    "        for i in range(0, self.docs_len, batch_size):\n",
    "            batch = self.docs[i : min(i + batch_size, self.docs_len)]\n",
    "            texts = [item[\"text\"] for item in batch]\n",
    "            docs_embs_batch = co.embed(\n",
    "                texts=texts, model=\"embed-english-v3.0\", input_type=\"search_document\"\n",
    "            ).embeddings\n",
    "            self.docs_embs.extend(docs_embs_batch)\n",
    "\n",
    "\n",
    "    def index(self) -> None:\n",
    "        \"\"\"\n",
    "        Indexes the documents for efficient retrieval.\n",
    "        \"\"\"\n",
    "        print(\"Indexing documents...\")\n",
    "\n",
    "        self.idx = hnswlib.Index(space=\"ip\", dim=1024)\n",
    "        self.idx.init_index(max_elements=self.docs_len, ef_construction=512, M=64)\n",
    "        self.idx.add_items(self.docs_embs, list(range(len(self.docs_embs))))\n",
    "\n",
    "        print(f\"Indexing complete with {self.idx.get_current_count()} documents.\")\n",
    "\n",
    "    def retrieve(self, query: str) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Retrieves document chunks based on the given query.\n",
    "    \n",
    "        Parameters:\n",
    "        query (str): The query to retrieve document chunks for.\n",
    "    \n",
    "        Returns:\n",
    "        List[Dict[str, str]]: A list of dictionaries representing the retrieved document chunks, with 'title', 'text', and 'url' keys.\n",
    "        \"\"\"\n",
    "\n",
    "        # Dense retrieval\n",
    "        query_emb = co.embed(\n",
    "            texts=[query], model=\"embed-english-v3.0\", input_type=\"search_query\"\n",
    "        ).embeddings\n",
    "\n",
    "        #print (\"Raw query results:\")\n",
    "        #print (self.idx.knn_query(query_emb, k=self.retrieve_top_k))\n",
    "        doc_ids = self.idx.knn_query(query_emb, k=self.retrieve_top_k)[0][0]\n",
    "        \n",
    "        #print (\"Doc IDs:\")\n",
    "        #print (doc_ids)\n",
    "\n",
    "        # Reranking\n",
    "        rank_fields = [\"title\", \"text\"] # We'll use the title and text fields for reranking\n",
    "\n",
    "        docs_to_rerank = [self.docs[doc_id] for doc_id in doc_ids]\n",
    "\n",
    "        #print (\"Documents to rerank:\")\n",
    "        #print (docs_to_rerank)\n",
    "\n",
    "        rerank_results = co.rerank(\n",
    "            query=query,\n",
    "            documents=docs_to_rerank,\n",
    "            top_n=self.rerank_top_k,\n",
    "            model=\"rerank-english-v3.0\",\n",
    "            rank_fields=rank_fields\n",
    "        )\n",
    "    \n",
    "        doc_ids_reranked = [doc_ids[result.index] for result in rerank_results.results]\n",
    "        #print(\"doc_ids_reranked:\")\n",
    "        #print(doc_ids_reranked)\n",
    "        #print(rerank_results.results[0].index)\n",
    "        #print(rerank_results.results[0].relevance_score)\n",
    "        #print (\"Re-ranked Documents:\")\n",
    "        #print (rerank_results)\n",
    "        \n",
    "        docs_retrieved = []\n",
    "        for doc_id in doc_ids_reranked:\n",
    "            docs_retrieved.append(\n",
    "                {\n",
    "                    \"title\": self.docs[doc_id][\"title\"],\n",
    "                    \"text\": self.docs[doc_id][\"text\"],\n",
    "                    \"url\": self.docs[doc_id][\"url\"],\n",
    "                }\n",
    "            )\n",
    "\n",
    "        return docs_retrieved\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-26T17:38:00.130176Z",
     "start_time": "2024-06-26T17:38:00.112475Z"
    }
   },
   "id": "3c411b8b35517d0f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Process the Documents\n",
    "We can now process the raw documents. We do that by creating an instance of Vectorstore. In our case, we get a total of 136 documents, chunked from the four web URLs."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ebb96fd97089627b"
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents...\n",
      "Embedding document chunks...\n",
      "Indexing documents...\n",
      "Indexing complete with 181 documents.\n"
     ]
    }
   ],
   "source": [
    "test_vectorstore = Vectorstore(raw_documents)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T20:09:21.958072Z",
     "start_time": "2024-06-27T20:09:14.573953Z"
    }
   },
   "id": "1b34614a448b3798"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test Retrieval\n",
    "Before going further, we first test the document retrieval part of the system. First, we create an instance of the Vectorstore with the raw documents that we have defined. Then, we use the retrieve method to retrieve the most relevant documents to the query multi-head attention definition."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80636aeda143d8fa"
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'title': 'Transformer Models',\n  'text': 'The attention step used in transformer models is actually much more powerful, and it’s called multi-head attention. In multi-head attention, several different embeddings are used to modify the vectors and add context to them. Multi-head attention has helped language models reach much higher levels of efficacy when processing and generating text.',\n  'url': 'https://docs.cohere.com/docs/transformer-models'},\n {'title': 'The Attention Mechanism',\n  'text': \"What you learned in this chapter is simple self-attention. However, we can do much better than that. There is a method called multi-head attention, in which one doesn't only consider one embedding, but several different ones. These are all obtained from the original by transforming it in different ways. Multi-head attention has been very successful at the task of adding context to text. If you'd like to learn more about the self and multi-head attention, you can check out the following two\",\n  'url': 'https://docs.cohere.com/docs/the-attention-mechanism'},\n {'title': 'Transformer Models',\n  'text': 'Attention is a very useful technique that helps language models understand the context. In order to understand how attention works, consider the following two sentences:\\n\\nSentence 1: The bank of the river.\\n\\nSentence 2: Money in the bank.',\n  'url': 'https://docs.cohere.com/docs/transformer-models'}]"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vectorstore.retrieve(\"multi-head attention definition\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T20:09:29.599610Z",
     "start_time": "2024-06-27T20:09:29.371588Z"
    }
   },
   "id": "6d85ee4e3ecbcc67"
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'title': 'Text Embeddings',\n  'text': 'What I would do, is locate it in point C, because it would make sense to have the word “Apple” close to the words “Banana”, “Strawberry”, and “Cherry”, and far from the other words such as “House”, “Car”, or “Tennis”. This is precisely a word embedding. And what are the numbers we are assigning to each word? Simply the horizontal and vertical coordinates of the location of the word. In this way, the word “Apple” is assigned to the numbers [5,5], and the word “Bicycle” to the coordinates [5,1].',\n  'url': 'https://docs.cohere.com/docs/text-embeddings'},\n {'title': 'Text Embeddings',\n  'text': 'What is a Word Embedding?\\n\\nBefore we get into what is a word embedding, let me test your intuition. In the figure underneath (Quiz 1), I have located 12 words in the plane. The words are the following:\\n\\nBanana\\n\\nBasketball\\n\\nBicycle\\n\\nBuilding\\n\\nCar\\n\\nCastle\\n\\nCherry\\n\\nHouse\\n\\nSoccer\\n\\nStrawberry\\n\\nTennis\\n\\nTruck\\n\\nNow, the question is, where would you locate the word “Apple” in this plane? There are many places it could go, but I’m allowing 3 possibilities labeled A, B, and C.',\n  'url': 'https://docs.cohere.com/docs/text-embeddings'},\n {'title': 'Similarity Between Words and Sentences',\n  'text': 'assigned very similar numbers, as they have the same semantic meaning.',\n  'url': 'https://docs.cohere.com/docs/similarity-between-words-and-sentences'}]"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vectorstore.retrieve(\"strawberry\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T20:09:34.982261Z",
     "start_time": "2024-06-27T20:09:34.740925Z"
    }
   },
   "id": "614a70cc810ae01d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create the Chatbot Component\n",
    "The Chatbot class handles the interaction between the user and the chatbot. It also handles the logic of the chatbot, including generating search queries based on a user message, and retrieving documents.\n",
    "\n",
    "The Chatbot class takes an instance of the Vectorstore class. We initialize a self.vectorstore attribute for that instance, as well as a unique conversation ID that we’ll need for each conversation.  \n",
    "\n",
    "### Get the User Message\n",
    "Next, we create a run() method that will be used to run the chatbot application. It begins with the logic for getting the user message, along with a way for the user to end the conversation."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c33a2e51de8af75"
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "class Chatbot:\n",
    "    def __init__(self, vectorstore: Vectorstore):\n",
    "        \"\"\"\n",
    "        Initializes an instance of the Chatbot class.\n",
    "\n",
    "        Parameters:\n",
    "        vectorstore (Vectorstore): An instance of the Vectorstore class.\n",
    "\n",
    "        \"\"\"\n",
    "        self.vectorstore = vectorstore\n",
    "        self.conversation_id = str(uuid.uuid4())\n",
    "        \n",
    "    def run(self):\n",
    "            \"\"\"\n",
    "            :param self: \n",
    "            :return: \n",
    "            \n",
    "            Runs the chatbot application\n",
    "            \"\"\"\n",
    "            while True:\n",
    "                # Get the user message\n",
    "                message = input (\"User: \")\n",
    "                \n",
    "                # Typing \"quit\" ends the conversation\n",
    "                if message.lower() == \"quit\":\n",
    "                    print (\"Ending chat.\")\n",
    "                    break\n",
    "                else:\n",
    "                    print (f\"User: {message}\")\n",
    "\n",
    "                # Generate search queries, if any\n",
    "                response = co.chat(message=message, search_queries_only=True)\n",
    "                \n",
    "                # if there are search queries, retrieve document chunks and respond\n",
    "                if response.search_queries:\n",
    "                    print (\"Retrieving information...\", end=\"\")\n",
    "                    \n",
    "                    # Retrieve document chunks for each query\n",
    "                    documents = []\n",
    "                    for query in response.search_queries:\n",
    "                        documents.extend(self.vectorstore.retrieve(query.text))\n",
    "                    \n",
    "                    # Use document chunks to respond\n",
    "                    response = co.chat_stream(\n",
    "                        message=message,\n",
    "                        model='command-r',\n",
    "                        documents=documents,\n",
    "                        conversation_id=self.conversation_id,\n",
    "                    )\n",
    "                # If there is no search query, directly respond\n",
    "                else:\n",
    "                    response = co.chat_stream(\n",
    "                        message=message,\n",
    "                        model=\"command-r\",\n",
    "                        conversation_id=self.conversation_id,\n",
    "                    )\n",
    "\n",
    "                # Print the chatbot response, citations, and documents\n",
    "                print(\"\\nChatbot:\")\n",
    "                citations = []\n",
    "                cited_documents = []\n",
    "\n",
    "                # Display response\n",
    "                for event in response:\n",
    "                    if event.event_type == \"text-generation\":\n",
    "                        print(event.text, end=\"\")\n",
    "                    elif event.event_type == \"citation-generation\":\n",
    "                        citations.extend(event.citations)\n",
    "                    elif event.event_type == \"search-results\":\n",
    "                        cited_documents = event.documents\n",
    "\n",
    "                # Display citations and source documents\n",
    "                if citations:\n",
    "                    print(\"\\n\\nCITATIONS:\")\n",
    "                    for citation in citations:\n",
    "                        print(citation)\n",
    "\n",
    "                    print(\"\\nDOCUMENTS:\")\n",
    "                    for document in cited_documents:\n",
    "                        print(document)\n",
    "\n",
    "                print(f\"\\n{'-'*100}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T20:10:03.757952Z",
     "start_time": "2024-06-27T20:10:03.752418Z"
    }
   },
   "id": "ba7c8c4e8bde0a4c"
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hello, I have a question\n",
      "\n",
      "Chatbot:\n",
      "Hello! What's your question? I'm here to help and I'll do my best to provide you with a helpful answer.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "User: what is the difference between word and sentence embedding\n",
      "Retrieving information...\n",
      "Chatbot:\n",
      "Word embeddings and sentence embeddings are both ways to associate words and sentences with vectors, which are lists of numbers. \n",
      "\n",
      "Word embeddings assign a list of numbers to each word. The semantic properties of a word are translated into the mathematical properties of the numbers. For example, similar words will be assigned similar vectors and dissimilar words will have vectors that are far away from each other.\n",
      "\n",
      "Sentence embeddings do the same thing but for sentences. Each sentence is associated with a vector in a coherent way. That is, similar sentences will be assigned similar vectors and different sentences will have different vectors.\n",
      "\n",
      "CITATIONS:\n",
      "start=0 end=15 text='Word embeddings' document_ids=['doc_1']\n",
      "start=20 end=39 text='sentence embeddings' document_ids=['doc_1']\n",
      "start=57 end=99 text='associate words and sentences with vectors' document_ids=['doc_0', 'doc_1', 'doc_2']\n",
      "start=111 end=128 text='lists of numbers.' document_ids=['doc_0', 'doc_1', 'doc_2']\n",
      "start=147 end=185 text='assign a list of numbers to each word.' document_ids=['doc_1', 'doc_2']\n",
      "start=190 end=219 text='semantic properties of a word' document_ids=['doc_2']\n",
      "start=224 end=283 text='translated into the mathematical properties of the numbers.' document_ids=['doc_2']\n",
      "start=297 end=343 text='similar words will be assigned similar vectors' document_ids=['doc_1', 'doc_2']\n",
      "start=348 end=417 text='dissimilar words will have vectors that are far away from each other.' document_ids=['doc_1', 'doc_2']\n",
      "start=439 end=475 text='do the same thing but for sentences.' document_ids=['doc_0', 'doc_1']\n",
      "start=476 end=517 text='Each sentence is associated with a vector' document_ids=['doc_0']\n",
      "start=523 end=531 text='coherent' document_ids=['doc_0']\n",
      "start=546 end=596 text='similar sentences will be assigned similar vectors' document_ids=['doc_0', 'doc_1']\n",
      "start=601 end=649 text='different sentences will have different vectors.' document_ids=['doc_0', 'doc_1']\n",
      "\n",
      "DOCUMENTS:\n",
      "{'id': 'doc_0', 'text': 'This is where sentence embeddings come into play. A sentence embedding is just like a word embedding, except it associates every sentence with a vector full of numbers, in a coherent way. By coherent, I mean that it satisfies similar properties as a word embedding. For instance, similar sentences are assigned to similar vectors, different sentences are assigned to different vectors, and most importantly, each of the coordinates of the vector identifies some (whether clear or obscure) property of', 'title': 'Text Embeddings', 'url': 'https://docs.cohere.com/docs/text-embeddings'}\n",
      "{'id': 'doc_1', 'text': 'In the previous chapters, you learned about word and sentence embeddings and similarity between words and sentences. In short, a word embedding is a way to associate words with lists of numbers (vectors) in such a way that similar words are associated with numbers that are close by, and dissimilar words with numbers that are far away from each other. A sentence embedding does the same thing, but associating a vector to every sentence. Similarity is a way to measure how similar two words (or', 'title': 'The Attention Mechanism', 'url': 'https://docs.cohere.com/docs/the-attention-mechanism'}\n",
      "{'id': 'doc_2', 'text': 'In the previous chapter, I explained the concept of word embeddings. In a nutshell, a word embedding is an assignment of a list of numbers (vector) to every word, in a way that semantic properties of the word translate into mathematical properties of the numbers. What do we mean by this? For example, two similar words will have similar vectors, and two different words will have different vectors. But most importantly, each entry in the vector corresponding to a word keeps track of some property', 'title': 'Similarity Between Words and Sentences', 'url': 'https://docs.cohere.com/docs/similarity-between-words-and-sentences'}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ending chat.\n"
     ]
    }
   ],
   "source": [
    "chatbot = Chatbot(test_vectorstore)\n",
    "\n",
    "chatbot.run()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T20:11:09.954624Z",
     "start_time": "2024-06-27T20:10:14.329036Z"
    }
   },
   "id": "735dd6601305f049"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "abf3c280a5410223"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
