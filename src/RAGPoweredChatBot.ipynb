{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T21:25:29.976089Z",
     "start_time": "2024-07-24T21:25:29.930405Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cohere\n",
    "import uuid\n",
    "import hnswlib\n",
    "from typing import List, Dict\n",
    "from unstructured.partition.html import partition_html\n",
    "from unstructured.chunking.title import chunk_by_title\n",
    "\n",
    "# Cohere API key\n",
    "api_key = 'BfTJNyke3jghhXpgRy6R1SSl8fRpso5o02i78moX'\n",
    "\n",
    "# Set up Cohere client\n",
    "co = cohere.Client(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eaf33457",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.text import partition_text\n",
    "\n",
    "elements = partition_text(filename=\"/Users/rohanchandra/Desktop/git/GSAHackathonTeam49/KnowledgeBase/can_order_food_safety_publications.txt\")\n",
    "\n",
    "with open(\"/Users/rohanchandra/Desktop/git/GSAHackathonTeam49/KnowledgeBase/can_order_food_safety_publications.txt\", \"r\") as f:\n",
    "  elements = partition_text(file=f)\n",
    "\n",
    "with open(\"/Users/rohanchandra/Desktop/git/GSAHackathonTeam49/KnowledgeBase/can_order_food_safety_publications.txt\", \"r\") as f:\n",
    "  text = f.read()\n",
    "elements = partition_text(text=text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdc7616f82e5506",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Create the VectorStore Component\n",
    "\n",
    "The Vectorstore class handles the ingestion of documents into embeddings (or vectors) and the retrieval of relevant documents given a query.\n",
    "\n",
    "As an example, we’ll use the contents from LLM University: What are Large Language Models? which explains the architecture of large language models. It consists of four web pages, each in the Python list raw_documents below. Each entry is identified by its title and URL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2aade2a2ccb41bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T21:25:40.502588Z",
     "start_time": "2024-07-24T21:25:40.474548Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_documents = [\n",
    "    {\n",
    "        \"title\": \"Food Supply Chains\",\n",
    "        \"url\": \"https://www.usda.gov/coronavirus/food-supply-chain\"},\n",
    "    {\n",
    "        \"title\": \"USDA Programs\",\n",
    "        \"url\": \"https://www.rd.usda.gov/programs-services/single-family-housing-programs/single-family-housing-direct-home-loans\"},\n",
    "    {\n",
    "        \"title\": \"Funding Opportunities\",\n",
    "        \"url\": \"https://www.usda.gov/media/press-releases/2022/08/24/usda-announces-550-million-american-rescue-plan-funding-projects\"},\n",
    "    # {\n",
    "    #     \"title\": \"Single Family Loan Program\",\n",
    "    #     \"url\": \"https://www.rd.usda.gov/programs-services/single-family-housing-programs/single-family-housing-guaranteed-loan-program\"},\n",
    "    # {\n",
    "    #     \"title\": \"Farm Loan Program\",\n",
    "    #     \"url\": \"https://www.fsa.usda.gov/programs-and-services/farm-loan-programs/\"},\n",
    "    # {\n",
    "    #     \"title\": \"Transformer Models\",\n",
    "    #     \"url\": \"https://docs.cohere.com/docs/transformer-models\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af5e01f6ff75801",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We implement this in the Vectorstore class below, which takes the raw_documents list as input.\n",
    "\n",
    "We also initialize a few instance attributes and methods. The attributes include self.raw_documents to represent the raw documents, self.docs to represent the chunked version of the documents, self.docs_embs to represent the embeddings of the chunked documents, and a couple of top_k parameters to be used for retrieval and reranking.\n",
    "\n",
    "Meanwhile, the methods include load_and_chunk(), embed(), and index() for ingesting raw documents. As you’ll see, we will also specify a retrieve() method to retrieve relevant document chunks given a query.\n",
    "\n",
    "## Load and Chunk the Documents\n",
    "The load_and_chunk() method loads the raw documents from the URL and breaks them into smaller chunks. Chunking for information retrieval is a broad topic in and of itself, with many strategies being discussed within the AI community. For our example, we’ll utilize the partition_html method from the unstructured library. Read its documentation for more information about its chunking approach.\n",
    "\n",
    "Each chunk is turned into a dictionary with three fields:\n",
    "\n",
    "title: The web page’s title\n",
    "text: The textual content of the chunk\n",
    "url: The web page’s URL\n",
    "This information will eventually be passed to the chatbot’s prompt for generating the response, so it’s crucial to populate relevant information into this dictionary. Note that we are not limited to these three fields. At a minimum, the Chat endpoint requires the text field, but beyond that, we can add custom fields that can provide more context about the document, such as subtitles, snippets, tags, and others.\n",
    "\n",
    "The resulting dictionaries are stored in the self.docs attribute.\n",
    "\n",
    "## Embed the Document Chunks\n",
    "The embed() method generates embeddings of the chunked documents. We use the Embed endpoint and Cohere's embed-english-v3.0 model. Since the endpoint has a limit of 96 documents per call, we send them in batches.\n",
    "\n",
    "With the Embed v3 model, we need to define an input_type, of which there are four options depending on the type of task. Using these input types ensures the highest possible quality for the respective tasks. Since our document chunks will be used for retrieval, we use search_document as the input_type.\n",
    "\n",
    "The resulting chunk embeddings are stored in the self.docs_embs attribute.\n",
    "\n",
    "## Index Document Chunks\n",
    "The index() method indexes the document chunk embeddings. We build an index to store the embeddings in a structured and organized way in order to ensure efficient similarity search during retrieval.\n",
    "\n",
    "There are many options available for building an index. For production environments, typically a vector database (like Weaviate or MongoDB) is required to handle the continuous process of indexing documents and maintaining the index.\n",
    "\n",
    "In our example, however, we’ll keep it simple and use a vector library instead. We can choose from many open-source projects, such as Faiss, Annoy, ScaNN, or Hnswlib, which is the one we’ll use. These libraries store embeddings in in-memory indexes and implement approximate nearest neighbor (ANN) algorithms to make similarity search efficient.\n",
    "\n",
    "The resulting document chunk embeddings are stored in the self.idx attribute.\n",
    "\n",
    "## Implement Retrieval\n",
    "The retrieve() method uses semantic search to retrieve relevant document chunks given a query, and it has two steps: (1) dense retrieval, (2) reranking.\n",
    "### Dense Retrieval\n",
    "We implement a dense retrieval system that leverages embeddings to retrieve document chunks, offering significant improvements over basic keyword-matching approaches. Embeddings can capture the contextual meaning of a document, thus enabling the retrieval of highly relevant results to the given query.\n",
    "\n",
    "We embed the query using the same embed-english-v3.0 model that we used to embed the document chunks, but this time, we set input_type=”search_query”.\n",
    "\n",
    "Search is performed by the knn_query() method from the hnswlib library. Given a query, it returns the document chunks most similar to the query. We define the number of document chunks to return using the attribute self.retrieve_top_k=10.\n",
    "\n",
    "### Reranking\n",
    "After dense retrieval, we implement a reranking step. While our dense retrieval component is already highly capable of retrieving relevant sources, the Rerank endpoint provides an additional boost to the quality of the search results, especially for complex and domain-specific queries. It takes the search results and sorts them according to their relevance to the query.\n",
    "\n",
    "We call the Rerank endpoint with co.rerank() and pass the query and the list of document chunks to be reranked. We also define the number of top reranked document chunks to retrieve using the attribute self.rerank_top_k=3. The model we use is rerank-english-v3.0, which lets you rerank documents that contain multiple fields, in the form of JSON objects. In our case, we'll use the title and text fields for reranking.\n",
    "\n",
    "This method returns the top retrieved document chunks as a Python list docs_retrieved, so that they can be passed to the chatbot, which we’ll implement next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c411b8b35517d0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T17:38:00.130176Z",
     "start_time": "2024-06-26T17:38:00.112475Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Vectorstore:\n",
    "    def __init__(self, raw_documents: List[Dict[str, str]]):\n",
    "        self.raw_documents = raw_documents\n",
    "        self.docs = []\n",
    "        self.docs_embs = []\n",
    "        self.retrieve_top_k = 10\n",
    "        self.rerank_top_k = 3\n",
    "        self.load_and_chunk()\n",
    "        self.embed()\n",
    "        self.index()\n",
    "        \n",
    "    def load_and_chunk(self) -> None:\n",
    "        \"\"\"\n",
    "        Loads the text from the sources and chunks the HTML content.\n",
    "        \"\"\"\n",
    "        print(\"Loading documents...\")\n",
    "\n",
    "        for raw_document in self.raw_documents:\n",
    "            elements = partition_html(url=raw_document[\"url\"])\n",
    "            chunks = chunk_by_title(elements)\n",
    "            for chunk in chunks:\n",
    "                self.docs.append(\n",
    "                    {\n",
    "                        \"title\": raw_document[\"title\"],\n",
    "                        \"text\": str(chunk),\n",
    "                        \"url\": raw_document[\"url\"],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    def embed(self) -> None:\n",
    "        \"\"\"\n",
    "        Embeds the document chunks using the Cohere API.\n",
    "        \"\"\"\n",
    "        print(\"Embedding document chunks...\")\n",
    "\n",
    "        batch_size = 90\n",
    "        self.docs_len = len(self.docs)\n",
    "        for i in range(0, self.docs_len, batch_size):\n",
    "            batch = self.docs[i : min(i + batch_size, self.docs_len)]\n",
    "            texts = [item[\"text\"] for item in batch]\n",
    "            docs_embs_batch = co.embed(\n",
    "                texts=texts, model=\"embed-english-v3.0\", input_type=\"search_document\"\n",
    "            ).embeddings\n",
    "            self.docs_embs.extend(docs_embs_batch)\n",
    "\n",
    "\n",
    "    def index(self) -> None:\n",
    "        \"\"\"\n",
    "        Indexes the documents for efficient retrieval.\n",
    "        \"\"\"\n",
    "        print(\"Indexing documents...\")\n",
    "\n",
    "        self.idx = hnswlib.Index(space=\"ip\", dim=1024)\n",
    "        self.idx.init_index(max_elements=self.docs_len, ef_construction=512, M=64)\n",
    "        self.idx.add_items(self.docs_embs, list(range(len(self.docs_embs))))\n",
    "\n",
    "        print(f\"Indexing complete with {self.idx.get_current_count()} documents.\")\n",
    "\n",
    "    def retrieve(self, query: str) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Retrieves document chunks based on the given query.\n",
    "    \n",
    "        Parameters:\n",
    "        query (str): The query to retrieve document chunks for.\n",
    "    \n",
    "        Returns:\n",
    "        List[Dict[str, str]]: A list of dictionaries representing the retrieved document chunks, with 'title', 'text', and 'url' keys.\n",
    "        \"\"\"\n",
    "\n",
    "        # Dense retrieval\n",
    "        query_emb = co.embed(\n",
    "            texts=[query], model=\"embed-english-v3.0\", input_type=\"search_query\"\n",
    "        ).embeddings\n",
    "\n",
    "        #print (\"Raw query results:\")\n",
    "        #print (self.idx.knn_query(query_emb, k=self.retrieve_top_k))\n",
    "        doc_ids = self.idx.knn_query(query_emb, k=self.retrieve_top_k)[0][0]\n",
    "        \n",
    "        #print (\"Doc IDs:\")\n",
    "        #print (doc_ids)\n",
    "\n",
    "        # Reranking\n",
    "        rank_fields = [\"title\", \"text\"] # We'll use the title and text fields for reranking\n",
    "\n",
    "        docs_to_rerank = [self.docs[doc_id] for doc_id in doc_ids]\n",
    "\n",
    "        #print (\"Documents to rerank:\")\n",
    "        #print (docs_to_rerank)\n",
    "\n",
    "        rerank_results = co.rerank(\n",
    "            query=query,\n",
    "            documents=docs_to_rerank,\n",
    "            top_n=self.rerank_top_k,\n",
    "            model=\"rerank-english-v3.0\",\n",
    "            rank_fields=rank_fields\n",
    "        )\n",
    "    \n",
    "        doc_ids_reranked = [doc_ids[result.index] for result in rerank_results.results]\n",
    "        #print(\"doc_ids_reranked:\")\n",
    "        #print(doc_ids_reranked)\n",
    "        #print(rerank_results.results[0].index)\n",
    "        #print(rerank_results.results[0].relevance_score)\n",
    "        #print (\"Re-ranked Documents:\")\n",
    "        #print (rerank_results)\n",
    "        \n",
    "        docs_retrieved = []\n",
    "        for doc_id in doc_ids_reranked:\n",
    "            docs_retrieved.append(\n",
    "                {\n",
    "                    \"title\": self.docs[doc_id][\"title\"],\n",
    "                    \"text\": self.docs[doc_id][\"text\"],\n",
    "                    \"url\": self.docs[doc_id][\"url\"],\n",
    "                }\n",
    "            )\n",
    "\n",
    "        return docs_retrieved\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb96fd97089627b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Process the Documents\n",
    "We can now process the raw documents. We do that by creating an instance of Vectorstore. In our case, we get a total of 136 documents, chunked from the four web URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b34614a448b3798",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T20:09:21.958072Z",
     "start_time": "2024-06-27T20:09:14.573953Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents...\n",
      "Embedding document chunks...\n",
      "Indexing documents...\n",
      "Indexing complete with 105 documents.\n"
     ]
    }
   ],
   "source": [
    "test_vectorstore = Vectorstore(raw_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80636aeda143d8fa",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Test Retrieval\n",
    "Before going further, we first test the document retrieval part of the system. First, we create an instance of the Vectorstore with the raw documents that we have defined. Then, we use the retrieve method to retrieve the most relevant documents to the query multi-head attention definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d85ee4e3ecbcc67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T20:09:29.599610Z",
     "start_time": "2024-06-27T20:09:29.371588Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Food Supply Chains',\n",
       "  'text': 'considered in accordance with the hierarchy.',\n",
       "  'url': 'https://www.usda.gov/coronavirus/food-supply-chain'},\n",
       " {'title': 'Food Supply Chains',\n",
       "  'text': 'worker health and safety.',\n",
       "  'url': 'https://www.usda.gov/coronavirus/food-supply-chain'},\n",
       " {'title': 'Food Supply Chains',\n",
       "  'text': 'A: USDA is monitoring the situation closely in collaboration with our federal and state partners. FNS is ready to assist in the government-wide effort to ensure all Americans have access to food in times of need. In the event of an emergency or disaster situation, FNS programs are just one part of a much larger government-wide coordinated response. All our programs, including SNAP, WIC, and the National School Lunch and Breakfast Programs, have flexibilities and contingencies built-in to allow',\n",
       "  'url': 'https://www.usda.gov/coronavirus/food-supply-chain'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vectorstore.retrieve(\"multi-head attention definition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "614a70cc810ae01d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T20:09:34.982261Z",
     "start_time": "2024-06-27T20:09:34.740925Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Funding Opportunities',\n",
       "  'text': 'help ensure underserved producers have the resources, tools, programs, and technical support they need to succeed.',\n",
       "  'url': 'https://www.usda.gov/media/press-releases/2022/08/24/usda-announces-550-million-american-rescue-plan-funding-projects'},\n",
       " {'title': 'Food Supply Chains',\n",
       "  'text': 'facilitate ongoing operations and support the food supply, while also mitigating the risk of spreading COVID-19.',\n",
       "  'url': 'https://www.usda.gov/coronavirus/food-supply-chain'},\n",
       " {'title': 'Food Supply Chains',\n",
       "  'text': 'considered in accordance with the hierarchy.',\n",
       "  'url': 'https://www.usda.gov/coronavirus/food-supply-chain'}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vectorstore.retrieve(\"strawberry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c33a2e51de8af75",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Create the Chatbot Component\n",
    "The Chatbot class handles the interaction between the user and the chatbot. It also handles the logic of the chatbot, including generating search queries based on a user message, and retrieving documents.\n",
    "\n",
    "The Chatbot class takes an instance of the Vectorstore class. We initialize a self.vectorstore attribute for that instance, as well as a unique conversation ID that we’ll need for each conversation.  \n",
    "\n",
    "### Get the User Message\n",
    "Next, we create a run() method that will be used to run the chatbot application. It begins with the logic for getting the user message, along with a way for the user to end the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba7c8c4e8bde0a4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T20:10:03.757952Z",
     "start_time": "2024-06-27T20:10:03.752418Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Chatbot:\n",
    "    def __init__(self, vectorstore: Vectorstore):\n",
    "        \"\"\"\n",
    "        Initializes an instance of the Chatbot class.\n",
    "\n",
    "        Parameters:\n",
    "        vectorstore (Vectorstore): An instance of the Vectorstore class.\n",
    "\n",
    "        \"\"\"\n",
    "        self.vectorstore = vectorstore\n",
    "        self.conversation_id = str(uuid.uuid4())\n",
    "        \n",
    "    def run(self):\n",
    "            \"\"\"\n",
    "            :param self: \n",
    "            :return: \n",
    "            \n",
    "            Runs the chatbot application\n",
    "            \"\"\"\n",
    "            while True:\n",
    "                # Get the user message\n",
    "                message = input (\"User: \")\n",
    "                \n",
    "                # Typing \"quit\" ends the conversation\n",
    "                if message.lower() == \"quit\":\n",
    "                    print (\"Ending chat.\")\n",
    "                    break\n",
    "                else:\n",
    "                    print (f\"User: {message}\")\n",
    "\n",
    "                # Generate search queries, if any\n",
    "                response = co.chat(message=message, search_queries_only=True)\n",
    "                \n",
    "                # if there are search queries, retrieve document chunks and respond\n",
    "                if response.search_queries:\n",
    "                    print (\"Retrieving information...\", end=\"\")\n",
    "                    \n",
    "                    # Retrieve document chunks for each query\n",
    "                    documents = []\n",
    "                    for query in response.search_queries:\n",
    "                        documents.extend(self.vectorstore.retrieve(query.text))\n",
    "                    \n",
    "                    # Use document chunks to respond\n",
    "                    response = co.chat_stream(\n",
    "                        message=message,\n",
    "                        model='command-r',\n",
    "                        documents=documents,\n",
    "                        conversation_id=self.conversation_id,\n",
    "                    )\n",
    "                # If there is no search query, directly respond\n",
    "                else:\n",
    "                    response = co.chat_stream(\n",
    "                        message=message,\n",
    "                        model=\"command-r\",\n",
    "                        conversation_id=self.conversation_id,\n",
    "                    )\n",
    "\n",
    "                # Print the chatbot response, citations, and documents\n",
    "                print(\"\\nChatbot:\")\n",
    "                citations = []\n",
    "                cited_documents = []\n",
    "\n",
    "                # Display response\n",
    "                for event in response:\n",
    "                    if event.event_type == \"text-generation\":\n",
    "                        print(event.text, end=\"\")\n",
    "                    elif event.event_type == \"citation-generation\":\n",
    "                        citations.extend(event.citations)\n",
    "                    elif event.event_type == \"search-results\":\n",
    "                        cited_documents = event.documents\n",
    "\n",
    "                # Display citations and source documents\n",
    "                if citations:\n",
    "                    print(\"\\n\\nCITATIONS:\")\n",
    "                    for citation in citations:\n",
    "                        print(citation)\n",
    "\n",
    "                    print(\"\\nDOCUMENTS:\")\n",
    "                    for document in cited_documents:\n",
    "                        print(document)\n",
    "\n",
    "                print(f\"\\n{'-'*100}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "735dd6601305f049",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T20:11:09.954624Z",
     "start_time": "2024-06-27T20:10:14.329036Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: I want to know about funding opportunities, technical assistance, and USDA programs that support rural communities\n",
      "Retrieving information...\n",
      "Chatbot:\n",
      "There are various funding opportunities and programs offered by the USDA to support rural communities.\n",
      "\n",
      "The U.S. Department of Agriculture (USDA) has announced up to $550 million in funding to support diverse projects for underserved producers. The projects aim to help them access land, capital, and markets and train a new generation of agricultural professionals. This funding is provided through the American Rescue Plan Act (ARPA).\n",
      "USDA also provides technical assistance and support for underserved producers including veterans, limited-resource producers, beginning farmers and ranchers, and those in high poverty areas. The support is offered through topics like business development, leadership, and management training. Additionally, there are partnership agreements worth at least $25 million in technical assistance for which applications are being accepted by USDA.\n",
      "\n",
      "CITATIONS:\n",
      "start=108 end=145 text='U.S. Department of Agriculture (USDA)' document_ids=['doc_2']\n",
      "start=166 end=178 text='$550 million' document_ids=['doc_2']\n",
      "start=193 end=217 text='support diverse projects' document_ids=['doc_2']\n",
      "start=222 end=244 text='underserved producers.' document_ids=['doc_2']\n",
      "start=275 end=308 text='access land, capital, and markets' document_ids=['doc_2']\n",
      "start=313 end=366 text='train a new generation of agricultural professionals.' document_ids=['doc_2']\n",
      "start=404 end=435 text='American Rescue Plan Act (ARPA)' document_ids=['doc_2']\n",
      "start=456 end=476 text='technical assistance' document_ids=['doc_1']\n",
      "start=481 end=488 text='support' document_ids=['doc_1']\n",
      "start=493 end=514 text='underserved producers' document_ids=['doc_1']\n",
      "start=525 end=533 text='veterans' document_ids=['doc_1']\n",
      "start=535 end=561 text='limited-resource producers' document_ids=['doc_1']\n",
      "start=563 end=593 text='beginning farmers and ranchers' document_ids=['doc_1']\n",
      "start=608 end=627 text='high poverty areas.' document_ids=['doc_1']\n",
      "start=671 end=691 text='business development' document_ids=['doc_1']\n",
      "start=693 end=703 text='leadership' document_ids=['doc_1']\n",
      "start=709 end=729 text='management training.' document_ids=['doc_1']\n",
      "start=754 end=776 text='partnership agreements' document_ids=['doc_0']\n",
      "start=792 end=803 text='$25 million' document_ids=['doc_0']\n",
      "start=807 end=827 text='technical assistance' document_ids=['doc_0']\n",
      "start=838 end=878 text='applications are being accepted by USDA.' document_ids=['doc_0']\n",
      "\n",
      "DOCUMENTS:\n",
      "{'id': 'doc_0', 'text': 'property. USDA also received applications for at least another $25 million in partnership agreements for technical assistance and will announce awardees by fall.', 'title': 'Funding Opportunities', 'url': 'https://www.usda.gov/media/press-releases/2022/08/24/usda-announces-550-million-american-rescue-plan-funding-projects'}\n",
      "{'id': 'doc_1', 'text': 'To date, USDA has implemented provisions within Section 1006 of the American Rescue Plan Act, including standing up an independent Equity Commission. USDA also has provided $75 million for partnership agreements with 20 organizations that will deliver technical assistance and support for underserved producers, including veterans, limited resources producers, beginning farmers and ranchers, and/or producers living in high poverty areas on topics ranging from business development to heirs’', 'title': 'Funding Opportunities', 'url': 'https://www.usda.gov/media/press-releases/2022/08/24/usda-announces-550-million-american-rescue-plan-funding-projects'}\n",
      "{'id': 'doc_2', 'text': 'WASHINGTON, Aug. 24, 2022 - The U.S. Department of Agriculture (USDA) announced today up to $550 million in funding to support projects that enable underserved producers to access land, capital, and markets, and train the next, diverse generation of agricultural professionals. These investments are made through funding provided in the American Rescue Plan Act (ARPA) Section 1006, as amended by Section 22007 of the Inflation Reduction Act. These provisions fund and direct USDA to take action to', 'title': 'Funding Opportunities', 'url': 'https://www.usda.gov/media/press-releases/2022/08/24/usda-announces-550-million-american-rescue-plan-funding-projects'}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "User: \n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "status_code: 400, body: {'message': 'invalid request: message must be at least 1 token long or tool results must be specified.'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m chatbot \u001b[38;5;241m=\u001b[39m Chatbot(test_vectorstore)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mchatbot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[33], line 32\u001b[0m, in \u001b[0;36mChatbot.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Generate search queries, if any\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_queries_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# if there are search queries, retrieve document chunks and respond\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39msearch_queries:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/personal/lib/python3.11/site-packages/cohere/client.py:103\u001b[0m, in \u001b[0;36mexperimental_kwarg_decorator.<locals>._wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_kwarg(deprecated_kwarg, kwargs):\n\u001b[1;32m     99\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeprecated_kwarg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` parameter is an experimental feature and may change in future releases.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo suppress this warning, set `log_warning_experimental_features=False` when initializing the client.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    102\u001b[0m     )\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/personal/lib/python3.11/site-packages/cohere/client.py:35\u001b[0m, in \u001b[0;36mvalidate_args.<locals>._wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs: typing\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: typing\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mAny:\n\u001b[1;32m     34\u001b[0m     check_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/personal/lib/python3.11/site-packages/cohere/base_client.py:855\u001b[0m, in \u001b[0;36mBaseCohere.chat\u001b[0;34m(self, message, model, preamble, chat_history, conversation_id, prompt_truncation, connectors, search_queries_only, documents, citation_quality, temperature, max_tokens, max_input_tokens, k, p, seed, stop_sequences, frequency_penalty, presence_penalty, raw_prompting, return_prompt, tools, tool_results, force_single_step, response_format, request_options)\u001b[0m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m typing\u001b[38;5;241m.\u001b[39mcast(NonStreamedChatResponse, construct_type(type_\u001b[38;5;241m=\u001b[39mNonStreamedChatResponse, object_\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mjson()))  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n\u001b[0;32m--> 855\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadRequestError(\n\u001b[1;32m    856\u001b[0m         typing\u001b[38;5;241m.\u001b[39mcast(typing\u001b[38;5;241m.\u001b[39mAny, construct_type(type_\u001b[38;5;241m=\u001b[39mtyping\u001b[38;5;241m.\u001b[39mAny, object_\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mjson()))  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     )\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m401\u001b[39m:\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnauthorizedError(\n\u001b[1;32m    860\u001b[0m         typing\u001b[38;5;241m.\u001b[39mcast(typing\u001b[38;5;241m.\u001b[39mAny, construct_type(type_\u001b[38;5;241m=\u001b[39mtyping\u001b[38;5;241m.\u001b[39mAny, object_\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mjson()))  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     )\n",
      "\u001b[0;31mBadRequestError\u001b[0m: status_code: 400, body: {'message': 'invalid request: message must be at least 1 token long or tool results must be specified.'}"
     ]
    }
   ],
   "source": [
    "chatbot = Chatbot(test_vectorstore)\n",
    "\n",
    "chatbot.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf3c280a5410223",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
